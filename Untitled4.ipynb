{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b190157-c414-403b-92cb-07fda12ef339",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tree_sitter import Language, Parser, Node\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "from typing import List\n",
    "import tiktoken\n",
    "\n",
    "\n",
    "class CppParser:\n",
    "    def __init__(self, language_path: str, code_root: str):\n",
    "        self.code_root = code_root\n",
    "        self.language = Language(language_path, 'cpp')\n",
    "        self.parser = Parser()\n",
    "        self.parser.set_language(self.language)\n",
    "\n",
    "    def get_function_name(self, node: Node) -> str:\n",
    "        if node.type == 'identifier':\n",
    "            return node.text.decode(\"utf-8\")\n",
    "\n",
    "        for child in node.children:\n",
    "            name = self.get_function_name(child)\n",
    "            if name:\n",
    "                return name\n",
    "        return None\n",
    "\n",
    "    def find_identifier(self, node: Node):\n",
    "        if node.type == 'identifier':\n",
    "            return node\n",
    "        for child in node.children:\n",
    "            found = self.find_identifier(child)\n",
    "            if found:\n",
    "                return found\n",
    "        return None\n",
    "\n",
    "    def get_function_code(self, node, source_code):\n",
    "        \"\"\"\n",
    "        Extract function code from a tree-sitter node of type 'function_definition'\n",
    "        \"\"\"\n",
    "        start_byte = node.start_byte\n",
    "        end_byte = node.end_byte\n",
    "        return source_code[start_byte:end_byte].decode('utf-8')\n",
    "\n",
    "    def get_functions(self, filepath):\n",
    "        filepath = os.path.abspath(filepath)  # Ensure the filepath is an absolute path\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            source_code = f.read().encode(\"utf-8\")\n",
    "        tree = self.parser.parse(source_code)\n",
    "        root_node = tree.root_node\n",
    "\n",
    "        def traverse(node, scope=None, class_name=None):\n",
    "            if node.type in ['public', 'private', 'protected']:\n",
    "                scope = node.type\n",
    "            if node.type == 'class_specifier':\n",
    "                class_name_node = self.find_identifier(node)\n",
    "                if class_name_node:\n",
    "                    class_name = class_name_node.text.decode(\"utf-8\")\n",
    "\n",
    "            if node.type == 'function_definition':\n",
    "                function_name = self.get_function_name(node)\n",
    "                code = source_code[node.start_byte:node.end_byte].decode(\"utf-8\")\n",
    "\n",
    "                yield {\n",
    "                    \"function_name\": function_name,\n",
    "                    \"filepath\": filepath,\n",
    "                    \"code\": code\n",
    "                }\n",
    "            for child in node.children:\n",
    "                yield from traverse(child)\n",
    "\n",
    "        yield from traverse(root_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ac646f-242a-4a98-a744-c2ec4eec0964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "# Set your OpenAI API key\n",
    "openai.api_key = \"your_api_key\"\n",
    "\n",
    "# Define retry function with backoff\n",
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def request_with_backoff(func, **kwargs):\n",
    "    return func(**kwargs)\n",
    "\n",
    "# Function for Completions endpoint\n",
    "def completions_with_backoff_and_batching(prompts, model=\"curie\", max_tokens=20, rate_limit_per_minute=3000):\n",
    "    delay = 60.0 / rate_limit_per_minute\n",
    "    stories = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        time.sleep(delay)\n",
    "        response = request_with_backoff(openai.Completion.create, model=model, prompt=prompt, max_tokens=max_tokens)\n",
    "        stories.append(prompt + response.choices[0].text)\n",
    "\n",
    "    return stories\n",
    "\n",
    "# Function for Embeddings endpoint\n",
    "def embeddings_with_backoff_and_batching(texts, rate_limit_per_minute=3000):\n",
    "    delay = 60.0 / rate_limit_per_minute\n",
    "    embeddings = []\n",
    "\n",
    "    for text in texts:\n",
    "        time.sleep(delay)\n",
    "        response = request_with_backoff(openai.Embedding.create, model=\"text-davinci-002\", text=text)\n",
    "        embeddings.append(response.embedding)\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "# Function for Code endpoint\n",
    "def code_with_backoff_and_batching(prompts, model=\"curie\", max_tokens=20, rate_limit_per_minute=20):\n",
    "    delay = 60.0 / rate_limit_per_minute\n",
    "    code_responses = []\n",
    "\n",
    "    for prompt in prompts:\n",
    "        time.sleep(delay)\n",
    "        response = request_with_backoff(openai.Code.create, model=model, prompt=prompt, max_tokens=max_tokens)\n",
    "        code_responses.append(prompt + response.choices[0].text)\n",
    "\n",
    "    return code_responses\n",
    "\n",
    "# Function for Edit endpoint\n",
    "def edit_with_backoff_and_batching(texts, model=\"curie\", rate_limit_per_minute=20):\n",
    "    delay = 60.0 / rate_limit_per_minute\n",
    "    edited_responses = []\n",
    "\n",
    "    for text in texts:\n",
    "        time.sleep(delay)\n",
    "        response = request_with_backoff(openai.Edit.create, model=model, text=text)\n",
    "        edited_responses.append(response.edited_text)\n",
    "\n",
    "    return edited_responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b75739-8311-4c55-8cda-dd336e8a5906",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import tiktoken\n",
    "\n",
    "class TokenHandler:\n",
    "    def __init__(self, model: str):\n",
    "        self.model = model\n",
    "        self.encoding = tiktoken.encoding_for_model(model)\n",
    "    \n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        token_list = self.encoding.encode(text)\n",
    "        return len(token_list)\n",
    "\n",
    "    def count_tokens_for_messages(self, messages: List[dict]) -> int:\n",
    "        num_tokens = 0\n",
    "        for message in messages:\n",
    "            num_tokens += self.count_tokens(message[\"content\"])\n",
    "        return num_tokens\n",
    "    \n",
    "    def tokenize(self, text: str) -> List[str]:\n",
    "        token_list = self.encoding.encode(text)\n",
    "        return token_list\n",
    "\n",
    "    def count_tokens(self, text: str) -> int:\n",
    "        token_list = self.tokenize(text)\n",
    "        return len(token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a889df0-526e-47b5-ad83-174053f0e57c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "class CostAnalyzer:\n",
    "    def __init__(self, token_count: int):\n",
    "        self.token_count = token_count\n",
    "        self.models = {\n",
    "            'Ada': {'v1': 0.0040, 'v2': 0.0004},\n",
    "            'Babbage': {'v1': 0.0050},\n",
    "            'Curie': {'v1': 0.0200},\n",
    "            'Davinci': {'v1': 0.2000}\n",
    "        }\n",
    "\n",
    "    def calculate_cost(self, model: str, version: str) -> float:\n",
    "        return (self.token_count / 1000) * self.models[model][version]\n",
    "\n",
    "    def print_costs(self):\n",
    "        print(\"Number of tokens: \" + str(self.token_count) + \"\\n\")\n",
    "        print(\"MODEL        VERSION       COST\")\n",
    "        print(\"----------------------------------------\")\n",
    "        \n",
    "        for model, versions in self.models.items():\n",
    "            for version, price in versions.items():\n",
    "                cost = self.calculate_cost(model, version)\n",
    "                print(f\"{model}\\t\\t{version}\\t$ {cost:.8f}\")\n",
    "                \n",
    "                \n",
    "    def calculate_all_costs(self) -> Dict[str, float]:\n",
    "        costs = {}\n",
    "        for model, versions in self.models.items():\n",
    "            for version, price in versions.items():\n",
    "                cost = self.calculate_cost(model, version)\n",
    "                costs[f\"{model}_{version}\"] = cost\n",
    "        return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f701fcc2-0266-4b1d-9ecb-005c87d79900",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Dict\n",
    "from openai.embeddings_utils import get_embedding, cosine_similarity\n",
    "import tiktoken\n",
    "\n",
    "class EmbeddingHandler:\n",
    "    def __init__(self, model: str, engine: str):\n",
    "        self.model = model\n",
    "        self.engine = engine\n",
    "        self.embeddings = {}  # Store embeddings as a dictionary\n",
    "\n",
    "    def create_embedding(self, text: str) -> Union[List[float], None]:\n",
    "        try:\n",
    "            embedding = get_embedding(text, engine=self.engine)\n",
    "            self.embeddings[text] = embedding\n",
    "            return embedding\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating embedding: {e}\")\n",
    "            return None\n",
    "\n",
    "    def get_embedding(self, text: str) -> Union[List[float], None]:\n",
    "        if text in self.embeddings:\n",
    "            return self.embeddings[text]\n",
    "        else:\n",
    "            token_count = self.token_handler.count_tokens(text)\n",
    "            # You can now use token_count for any purpose, like cost estimation.\n",
    "            return self.create_embedding(text)\n",
    "\n",
    "    def cosine_similarity(self, embedding1: List[float], embedding2: List[float]) -> float:\n",
    "        return cosine_similarity(embedding1, embedding2)\n",
    "\n",
    "    def search_similar(self, df, query: str, n: int = 3, pprint: bool = True, n_lines: int = 7) -> pd.DataFrame:\n",
    "        query_embedding = self.get_embedding(query)\n",
    "\n",
    "        if query_embedding is None:\n",
    "            print(\"Error creating query embedding.\")\n",
    "            return pd.DataFrame()\n",
    "\n",
    "        df['similarities'] = df.code_embedding.apply(lambda x: self.cosine_similarity(x, query_embedding))\n",
    "        res = df.sort_values('similarities', ascending=False).head(n)\n",
    "\n",
    "        if pprint:\n",
    "            for r in res.iterrows():\n",
    "                print(r[1].filepath + \":\" + r[1].function_name + \"  score=\" + str(round(r[1].similarities, 3)))\n",
    "                print(\"\\n\".join(r[1].code.split(\"\\n\")[:n_lines]))\n",
    "                print('-' * 70)\n",
    "\n",
    "        return res\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_token_count(text: str) -> int:\n",
    "        tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "        tokens = []\n",
    "        try:\n",
    "            tokens = list(tokenizer.encode(text))\n",
    "        except TokenizerException as e:\n",
    "            print(f\"Error tokenizing text: {e}\")\n",
    "        return len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c50e1-ffe0-4467-b820-bbbe550e7ad1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set the paths\n",
    "language_path = 'C:\\\\Users\\\\newhi\\\\source\\\\repos\\\\Tree-Sitter\\\\tree-sitter-cpp\\\\parser.dll' # Update this with the path to your tree-sitter language .so file\n",
    "code_root = \"D:\\\\TestCodeParse\" # Update this with the path to your codebase\n",
    "engine = \"text-embedding-ada-002\" # Or any other engine you want to use\n",
    "model = \"ada\" # Or any other model you want to use\n",
    "\n",
    "# Instantiate the classes\n",
    "cpp_parser = CppParser(language_path, code_root)\n",
    "embedding_handler = EmbeddingHandler(model, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c65e42-f1a7-4832-96c6-8ac600eea48d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Parse the codebase\n",
    "functions_data = []\n",
    "for filepath in glob(os.path.join(code_root, \"**/*.cpp\"), recursive=True):\n",
    "    for function in cpp_parser.get_functions(filepath):\n",
    "        functions_data.append(function)\n",
    "df = pd.DataFrame(functions_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24721cf7-4e98-4355-9e56-9c664e2664a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa777ac3-1f8e-44d5-a0da-e84f85975a70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Analyze the cost\n",
    "n_tokens = sum(embedding_handler.get_token_count(func['code']) for func in functions_data)\n",
    "cost_analyzer = CostAnalyzer(n_tokens)\n",
    "cost_analyzer.print_costs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4944e3a7-6d3e-4973-9c46-ae71fc518ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings if the cost is okay\n",
    "decision = input(\"Do you want to proceed with creating embeddings? (y/n): \")\n",
    "if decision.lower() == 'y':\n",
    "    df['code_embedding'] = df['code'].apply(embedding_handler.get_embedding)\n",
    "else:\n",
    "    print(\"Embeddings not created.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
